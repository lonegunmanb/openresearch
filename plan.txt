基于 GitHub Copilot CLI 与 MCP 协议的纯命令行自主深度研究架构设计报告
1. 执行摘要与架构范式演进
在生成式人工智能（GenAI）向代理式人工智能（Agentic AI）演进的浪潮中，深度研究（Deep Research）系统代表了当前认知自动化的最高水平。传统的检索增强生成（RAG）技术虽然解决了知识截止和幻觉问题，但其本质仍是单次的“检索-生成”线性过程，缺乏处理复杂长尾问题所需的多步推理、自我纠错和跨源验证能力。Google 发布的 Gemini Deep Research 展示了一种通过长时程推理（Test-Time Compute）和异步任务编排来实现深度认知的可能性 1。然而，现有的深度研究实现往往依赖复杂的编译型语言（如 Go、Rust）或庞大的应用服务器框架（如 LangChain、AutoGPT），这提高了部署门槛并降低了系统的透明度。
本报告提出并详尽设计了一种纯命令行（CLI-Native）的自主深度研究架构。该架构彻底摒弃了传统的应用程序代码编写，转而利用GitHub Copilot CLI 作为通用的认知推理引擎，配合 Shell 脚本作为胶水逻辑，以及 Markdown 文件作为持久化状态机。这种设计理念回归了 Unix 哲学的核心——“一切皆文件”与“小工具组合”，通过文本流（Text Streams）和标准输入输出（Stdio）实现复杂的智能体编排。
本架构的核心创新在于将 GitHub Copilot CLI 从一个辅助编码工具重塑为一个自主递归推理机。通过集成模型上下文协议（Model Context Protocol, MCP），CLI Agent 获得了操作 Headless 浏览器、读写文件系统和执行系统命令的物理能力 2。系统利用一个结构化的 task.md 文件作为“共享内存”和“控制平面”，通过一个基于 Shell 的递归循环（即 Ralph Loop 模式 4）不断读取状态、规划行动、执行工具并更新状态，直至达成研究目标。本报告将从目录结构、状态机设计、多智能体角色定义、MCP 工具链配置及闭环控制逻辑五个维度，提供一份字数约为 15,000 字的详尽技术蓝图。
2. 理论框架：基于文本的认知状态机
在构建无需编写编译型代码的 Agent 系统时，状态管理是最大的挑战。传统的软件工程依赖内存中的数据结构（Structs, Classes）或数据库来维护状态，而在本架构中，我们将状态完全文本化。
2.1 文本即状态（Text-as-State）的设计哲学
本系统采用“Markdown 驱动开发”的理念，将应用程序的运行状态、历史记忆、计划队列和输出结果全部序列化为一个单一的 Markdown 文件 (task.md)。这不仅是数据的存储格式，更是 Agent 的“认知视窗”。
这种设计受到 AGENTS.md 模式的启发，即通过标准化的文档向 AI 传达上下文和指令 5。然而，本架构更进一步，将静态的指令文件转变为动态的状态机（Finite State Machine, FSM）。
可观测性：任何时刻查看 task.md，都能确切知道 Agent 处于什么阶段（Planning, Executing, Reflecting）。
可干预性：用户可以通过简单的文本编辑器（如 Vim, Nano）修改 task.md 中的待办事项或纠正错误信息，Agent 在下一次迭代中会自动适应新的状态。这种“人在回路（Human-in-the-Loop）”的机制是通过文件系统天然实现的，无需构建复杂的 UI 1。
持久性：由于状态即文件，系统天然具备断点续传能力。如果 Shell 脚本崩溃或终端关闭，重新运行脚本即可从 task.md 记录的最后一个状态无缝继续。
2.2 有向无环图（DAG）的文本化表达
深度研究任务通常是非线性的，需要分解为并行或依赖的子任务。Gemini Deep Research 通过 Interactions API 维护了一个复杂的异步任务图 1。在纯文本环境中，我们利用 Markdown 的任务列表语法（Task Lists）结合缩进和元数据标记来模拟 DAG。
例如：
[x] 任务 A：初步信息搜集 (ID: T1)
[ ] 任务 B：分析 T1 结果中的财务数据 (ID: T2, DependsOn: T1)
[ ] 任务 C：验证 T1 结果中的市场传言 (ID: T3, DependsOn: T1)
[ ] 任务 D：综合报告 (ID: T4, DependsOn: T2, T3) 根编排器 Agent 被训练为解析这种文本结构：只有当依赖项（DependsOn）所指向的任务被标记为 [x] 时，后续任务才具备“可执行（Runnable）”资格。这种文本化的依赖管理避免了复杂的图算法代码，完全依赖 LLM 的语义理解能力来维护逻辑顺序 7。
3. 系统物理架构与目录设计
为了实现环境隔离和操作的安全性，每个研究任务都在独立的沙箱目录中运行。该目录不仅包含状态文件，还包含原始资料、日志和特定于该任务的 MCP 配置。
3.1 标准化目录结构
系统启动脚本 init_research.sh 将创建如下标准结构：
~/deep-research-workspace/
├──_Topic_Name/
│ ├── task.md # 核心状态机与上下文存储
│ ├── report.md # 最终输出的综合报告
│ ├──.copilot/ # Copilot CLI 的局部配置
│ │ ├── mcp-config.json # 任务级 MCP 服务器配置
│ │ └── config.json # 模型参数（如温度、推理模型选择）
│ ├── artifacts/ # 原始资料归档（防丢失/溯源）
│ │ ├── web/ # 网页 HTML 快照
│ │ ├── pdf/ # 下载的 PDF 文件
│ │ └── images/ # 提取的图表
│ ├── logs/ # 执行日志（用于调试与审计）
│ │ ├── loop.log # 主循环的 Shell 输出
│ │ └── thought_stream.md # Agent 的思维链记录（CoT）
│ └── tools/ # 临时生成的辅助脚本（如 Python 数据处理脚本）
关键设计决策分析：
.copilot/mcp-config.json 的局部化：虽然 GitHub Copilot CLI 允许全局配置 MCP，但在深度研究场景中，不同任务可能需要不同的工具集（例如，金融研究需要 Bloomberg MCP，而技术研究需要 GitHub MCP）。通过在项目根目录放置局部配置文件，我们利用了 CLI 对项目级配置的优先加载特性 8，确保了工具权限的最小化原则。
artifacts/ 的物理隔离：为了复刻 Gemini 的溯源能力 1，Agent 不仅要在 task.md 中记录链接，必须下载原始文件的快照。这解决了“链接失效（Link Rot）”问题，并允许后续的“阅读 Agent”在本地对长文档（如财报 PDF）进行深度解析，避免重复消耗网络带宽和 tokens。
3.2 task.md 模板详解：状态机的Schema
task.md 文件不仅仅是笔记，它是一个结构严格的数据库。我们利用 Markdown 的Frontmatter (YAML) 存储机器可读的元数据，利用 Heading (#) 分隔不同的上下文区域。
task.md 模板规范：
mission_id: "DR-20240520-001" created_at: "2024-05-20T10:00:00Z" status: "PLANNING" # 枚举值: PLANNING, RESEARCHING, REFLECTING, SYNTHESIZING, COMPLETED, ERROR topic: "分析 2025 年全球固态电池供应链的瓶颈与机遇" iteration: 0 max_iterations: 50 cost_tracking: total_tokens: 0 tools_used: 0
1. 研究目标与约束 (Directives)
这是一个只读区域，定义了用户的原始需求和必须遵守的边界条件。
核心问题: 固态电池量产的主要供应链瓶颈是什么？
输出格式: 深度行业分析报告（Markdown）
约束: 必须引用 2024 年以后的数据；必须包含中、美、日三方的对比；禁止引用无来源的自媒体文章。
2. 执行计划 (DAG Scheduler)
动态更新区域。根 Agent 根据此列表调度子任务。
[ ] P1: 意图拆解: 将核心问题拆解为原材料、制造设备、工艺三个维度的子问题。(Status: PENDING)
[ ] S1: 广度搜索: 针对原材料（锂、硫化物）进行全网搜索。(Status: BLOCKED, DependsOn: P1)
[ ] R1: 深度阅读: 下载并分析 Toyota 和 CATL 的最新技术白皮书。(Status: BLOCKED, DependsOn: S1)
[ ] C1: 冲突消解: 对比不同研报对“量产时间点”的预测差异。(Status: BLOCKED, DependsOn: R1)
3. 信息知识图谱 (Knowledge Graph)
结构化的事实存储。所有子 Agent 的搜索结果必须追加到此，而非覆盖。
3.1 原材料维度
[Fact-001] 硫化物电解质的成本目前为 $500/kg，目标是降至 $50/kg。
Source: (Toyota Technical Review 2024)
Confidence: High
Raw_File: artifacts/web/toyota_review.html
3.2 制造设备维度
(待填充...)
4. 来源注册表 (Source Registry)
唯一真实数据源索引，用于生成引用。
ID
URL
Title
Type
Access Date
Local Path
S1
https://...
Toyota Review
PDF
2024-05-20
artifacts/pdf/s1.pdf

5. 反思与暂存区 (Scratchpad)
Agent 的思维链缓存。用于记录当前的困惑、发现的矛盾或下一步的策略调整。
Iteration 1: 用户的问题范围很广，建议先锁定“硫化物”和“氧化物”两条技术路线进行对比。
Gap Analysis: 目前缺乏关于 2025 年具体产能规划的数据，需要增加针对性搜索。
此模板的设计直接对标了 Gemini Deep Research 的内部数据结构 1：
Frontmatter 对应其 Interactions API 的会话元数据。
执行计划 对应其后台的异步任务队列。
知识图谱 对应其上下文窗口中的碎片化信息聚合。
来源注册表 是实现“细粒度引用（Fine-grained Citation）”的基础。
4. 多智能体角色定义与 Prompt 工程
尽管我们只使用一个二进制文件（copilot CLI），但通过传递不同的系统提示词（System Prompts），我们可以实例化出具有不同功能和权限的虚拟智能体。这是“单模型、多角色（Single Model, Multi-Persona）”架构的典型应用 9。
我们在 Shell 脚本中定义这些 Prompt 模板，并在调用 copilot -p 时动态注入。
4.1 根编排器 Agent (The Root Orchestrator)
角色定义：它是项目经理，负责“读”状态、“改”计划、“派”任务。它不直接联网搜索，只负责逻辑流转。
复刻能力：对应 Gemini 的 Gemini 2.0 Flash Thinking 模型，负责快速规划和意图消歧 1。
Prompt 设计：
你是一个深度研究任务的【根编排器】。你的唯一输入是 task.md 文件的内容。
你的职责是：
读取 YAML Frontmatter 中的 status。
检查 # 2. 执行计划 (DAG Scheduler) 中的任务状态。
根据依赖关系（DependsOn），找到优先级最高的一个未完成任务（[ ]）。
生成一条具体的 Shell 命令来唤起相应的子 Agent（搜索、阅读或反思 Agent）去执行该任务。
决策逻辑：
如果 status 是 "PLANNING" -> 唤起【规划 Agent】完善 DAG。
如果 status 是 "RESEARCHING" 且存在未完成的搜索任务 -> 唤起【执行 Agent】。
如果 status 是 "RESEARCHING" 但所有搜索任务已完成 -> 将 status 改为 "REFLECTING"。
如果 status 是 "REFLECTING" -> 唤起【反思 Agent】检查信息完整性。
如果 status 是 "SYNTHESIZING" -> 唤起【综合 Agent】撰写报告。
输出限制：你只能输出一段可执行的 Shell 脚本代码（通常是 copilot -p... 命令）。不要输出任何解释性文字。
4.2 规划 Agent (The Planner)
角色定义：负责初始化或动态调整 DAG。当遇到未知领域或死胡同时，它会被唤醒重写计划。
Prompt 关键点：
要求其使用广度优先搜索（BFS）策略将大问题拆解。
强制其输出 Markdown Checkbox 格式。
要求其明确依赖关系（DependsOn），以构建合法的 DAG。
4.3 执行 Agent (The Executor - Search & Read)
角色定义：它是工兵，拥有使用 MCP 工具的权限。它负责操作 Headless 浏览器、下载文件、解析内容。
复刻能力：对应 Gemini 的 Gemini 3 Pro 模型，具备长上下文处理能力和多模态读取能力 1。
Prompt 设计：
你是一个【执行 Agent】。当前任务是："{current_task}"。
你拥有当前环境中配置的所有 MCP 工具权限（包括但不限于：浏览器自动化、文件系统访问、文档解析等）。
执行步骤：
分析任务需求，构建 3-5 个高精度的搜索 Query。
根据可用的 MCP 工具选择最合适的方式进行信息搜集（如网页搜索、API 调用等）。
深度阅读：对于高相关性的结果（特别是 PDF 或 官方报告），使用 browser_navigate 获取全文。
数据提取：从文中提取关键数据点，必须保留来源 URL。
状态更新：
将提取的事实追加到 task.md 的 "知识图谱" 章节。
将新发现的来源追加到 "来源注册表"。
如果任务完成，将 DAG 中的该条目标记为 [x]。
注意：不要覆盖 task.md 的其他部分，仅使用追加（Append）操作或精确替换。
4.4 反思 Agent (The Reflector)
角色定义：它是质量控制员。它不产生新信息，而是评估现有信息的质量。
复刻能力：对应 Gemini 的“停止准则”和“反思机制” 1。它解决“什么时候才算搜够了”的问题。
Prompt 设计：
你是一个【反思 Agent】。请阅读 task.md 中的 "知识图谱" 和 "研究目标"。
执行自我评估 (Self-Correction)：
完整性检查：当前收集的信息是否足以回答核心问题？如果缺口（Gap），请在 DAG 中新增具体的搜索任务。
冲突检测：是否存在相互矛盾的数据（例如不同来源对同一数值的报道不一致）？如果有，生成一个 "冲突消解" 任务。
幻觉检查：检查所有事实是否有对应的 Source ID。
输出决策：
如果信息不足 -> 将 status 重置为 "RESEARCHING"。
如果信息充足且一致 -> 将 status 更新为 "SYNTHESIZING"。
在 "Scratchpad" 区域记录你的评估理由。
4.5 综合 Agent (The Synthesizer)
角色定义：它是最终报告的撰写者。
复刻能力：对应 Gemini 的报告生成和跨源冲突消解 1。
Prompt 设计：
要求其严格基于 "知识图谱" 写作，禁止利用自身预训练知识编造事实。
要求使用 `` 格式进行细粒度引用。
对于冲突数据，要求明确指出：“来源 S1 声称 X，而来源 S2 声称 Y，考虑到 S1 的权威性，本文采用 X”。
5. MCP 工具链配置与 Shell Skills
Copilot CLI 的强大之处在于它可以通过 Model Context Protocol (MCP) 扩展能力。为了实现深度研究，我们需要配置两类关键的 MCP Server：Headless 浏览器 和 文件系统访问。由于我们要在 Shell 中运行，必须使用 stdio 模式的 MCP Server，以便 CLI 进程可以通过标准输入输出与其通信，而无需复杂的 HTTP 网络配置 2。
5.1 MCP 配置文件 (mcp-config.json)
我们需要创建一个本地的 MCP 配置文件，并将其路径传递给 Copilot CLI。

JSON


{
  "mcpServers": {
    "browser_automation": {
      "type": "stdio",
      "command": "npx",
      "args": ["-y", "@anthropic-ai/mcp-server-playwright"]
      // 具体工具由 MCP Server 动态暴露，无需硬编码
    },
    "filesystem_control": {
      "type": "stdio",
      "command": "npx",
      "args": [
        "-y",
        "@modelcontextprotocol/server-filesystem",
        "${cwd}"
      ],
      "tools": ["read_file", "write_file", "append_file", "list_directory"]
    },
    "document_parser": {
      "type": "stdio",
      "command": "uvx",
      "args": [
        "mcp-md-pdf"
      ],
      "tools": ["pdf_to_markdown"]
    }
  }
}


关键配置解析：
Browser Server（如 Playwright MCP 或其他浏览器自动化 MCP）：这是"眼睛"。具体工具由所选 MCP Server 动态提供，可能包括但不限于：
- 网页搜索与导航能力
- 页面内容提取与快照
- 文件下载能力
- 表单交互与自动化操作
Agent 应根据实际可用的 MCP 工具灵活选择执行策略 12。
Filesystem Server (server-filesystem)：这是“手”。它限制 Agent 只能访问当前工作目录 (${cwd})，防止 Agent 意外修改系统文件 15。
append_file: 对于日志和知识图谱的更新，追加模式比覆盖模式更安全。
Document Parser (mcp-md-pdf)：这是“阅读器”。用于将下载的 PDF 转换为 Agent 可读的 Markdown 文本 16。
5.2 Shell Skills 与自动化授权
为了让自动化循环跑通，必须解决 Copilot CLI 默认的“请求确认”机制。我们需要使用 --allow-all-tools (或某些版本中的 --yolo 标志) 来授权 Agent 自主执行 MCP 工具 17。
此外，我们可以定义一些 Shell Aliases 来简化 Agent 的调用，将其封装为一种“伪 API”：

Bash


# 封装 Copilot CLI 调用，注入当前目录的 MCP 配置
alias agent_exec='copilot --allow-all-tools --additional-mcp-config.copilot/mcp-config.json -p'


6. 闭环控制系统的实现 (The Ralph Loop)
这是架构中唯一的“代码”部分——一个 Bash 脚本 (orchestrator.sh)。它实现了基于状态机的无限循环，直到任务完成。这个循环逻辑直接借鉴了 "Ralph Loop" 模式 4，即“读取状态 -> 思考 -> 执行 -> 观察 -> 循环”。
6.1 核心编排脚本逻辑

Bash


#!/bin/bash

# 配置变量
TASK_FILE="task.md"
MAX_ITERATIONS=50
LOG_FILE="logs/loop.log"

# 初始化函数
init_mission() {
    if; then
        echo "初始化任务文件..."
        cp templates/task_template.md $TASK_FILE
        # 这里可以使用 sed 将用户输入的 Query 注入到 task.md 的 topic 字段
    fi
}

# 主循环
run_loop() {
    local iter=0
    while; do
        echo "=== Iteration $iter ===" | tee -a $LOG_FILE
        
        # 1. 读取当前状态 (State Observation)
        # 使用 grep 提取 status 字段，这比解析 JSON 更鲁棒
        current_status=$(grep "^status:" $TASK_FILE | awk -F'"' '{print $2}')
        echo "当前状态: $current_status" | tee -a $LOG_FILE
        
        # 2. 终止条件检查 (Stopping Criteria)
        if; then
            echo "研究任务已完成！"
            exit 0
        elif; then
            echo "任务出错，请人工介入。"
            exit 1
        fi

        # 3. 根 Agent 决策 (The Brain)
        # 将 task.md 内容通过管道喂给 Root Agent Prompt
        # Root Agent 的输出将是一条 Shell 命令
        echo "根 Agent 正在规划..."
        NEXT_COMMAND=$(cat $TASK_FILE | copilot \
            --additional-mcp-config.copilot/mcp-config.json \
            --allow-all-tools \
            -p "$(cat prompts/root_agent_prompt.txt)")
        
        # 4. 记录决策 (Logging)
        echo "执行命令: $NEXT_COMMAND" >> $LOG_FILE
        
        # 5. 执行命令 (Action)
        # 这里存在安全风险，生产环境需增加命令白名单过滤
        # eval 将执行 Root Agent 生成的 'copilot -p...' 命令，即唤起子 Agent
        eval "$NEXT_COMMAND"
        
        # 6. 状态迭代
        iter=$((iter+1))
        # 更新 iteration 计数器
        sed -i "s/iteration:.*/iteration: $iter/" $TASK_FILE
        
        # 避免 API 速率限制
        sleep 5
    done
}

init_mission
run_loop


6.2 闭环控制的关键细节
递归调用 (Inception)：
根 Agent 输出的 $NEXT_COMMAND 通常是另一个 copilot 命令。例如：
Bash
copilot -p "你现在是【搜索 Agent】。请读取 task.md 中 ID 为 T1 的任务，使用可用的 MCP 工具进行信息搜集..." --allow-all-tools

这意味着我们是在用一个 LLM (Root) 去写另一个 LLM (Sub-Agent) 的 Prompt。这种**元提示（Meta-Prompting）**技术确保了上下文的动态传递。
错误恢复 (Self-Healing)： 如果子 Agent 执行失败（例如网络超时），它会在 task.md 的 Scratchpad 中记录错误。下一次循环时，根 Agent 会读取到这个错误，并决定是重试、切换线路还是标记任务失败。这复刻了 Gemini 遇到死胡同时的“回溯（Backtracking）”机制 1。
并发控制：
虽然 Shell 脚本通常是串行的，但我们可以通过在 $NEXT_COMMAND 后添加 & 符号来实现简单的并行（Parallelism）。根 Agent 可以一次性生成多个命令：
Bash
copilot -p "..." & 
copilot -p "..." & 
wait

这允许同时搜集多个维度的信息，显著提升效率。
7. 复刻 Gemini Deep Research 的关键能力
本架构通过特定的 Prompt 设计和工具组合，在 CLI 环境中实现了 Gemini 的核心特性。
7.1 跨源冲突消解 (Cross-Source Conflict Resolution)
Gemini 使用证据加权算法来解决冲突 1。我们在【综合 Agent】和【反思 Agent】中实现了类似的逻辑：
源信度评分：当 Agent 通过 MCP 工具获取网页内容时，要求其分析域名后缀（.gov,.edu vs.com）和网站声誉，并在 Knowledge Graph 中为每条事实标注 (Confidence: High/Medium/Low)。
显式矛盾呈现：Prompt 强制要求：“如果发现 Source A 与 Source B 冲突，必须在报告中明确写出‘关于 X 存在争议：A 指出...而 B 指出...’，并根据信度评分给出建议倾向。”
7.2 溯源与反幻觉 (Grounding & Anti-Hallucination)
Gemini 的 Interactions API 强制保存所有上下文以支持回溯 1。
物理存储：我们将所有爬取的网页和 PDF 保存到 artifacts/ 目录。
索引一致性：task.md 中的 Source Registry 表是唯一真理源。Agent 被禁止引用不在该表中的来源。
引用检查：在【反思 Agent】的 Prompt 中加入正则检查指令：检查所有论断是否都跟随了 格式的引用标签。如果没有，拒绝进入 SYNTHESIZING 状态。
7.3 停止准则 (Stopping Criteria)
DeepSearchQA 研究表明，Agent 往往不知道何时停止 1。
双重检查机制：我们不单纯依赖 LLM 的自我评估，而是结合了结构化检查。
覆盖率检查：DAG 中的所有任务是否都标记为 [x]？
信息饱和度检查：【反思 Agent】被专门设计来寻找“信息缺口”。Prompt 指令：“假设你是最苛刻的审稿人，你能找出报告中哪些结论缺乏数据支持？如果有，请提出新的搜索任务。”
硬性边界：MAX_ITERATIONS 常量防止了无限循环造成的 Token 浪费。
8. 结论与展望
本报告详细阐述了如何仅利用 Shell 环境和 GitHub Copilot CLI 构建一个能够媲美 SaaS 级深度研究产品的自主 Agent 系统。通过将 State（状态）文本化、Tools（工具）标准化（MCP） 以及 Logic（逻辑）脚本化，我们解构了复杂的 Agentic AI 应用。
该架构的优势在于：
极简主义与透明度：没有隐藏的数据库或黑盒代码，所有思考过程和数据都以 Markdown 形式存在，完全透明且易于审计。
高度可扩展：通过添加新的 MCP Server（如数据库连接器、代码执行器），该架构可以轻松从“行业研究”扩展到“代码审计”或“系统运维”领域。
开发者友好：利用开发者最熟悉的 CLI 和 Markdown 工具链，降低了构建自主智能体的门槛。
这种“Shell-Native Agent”的设计范式，预示着未来操作系统交互方式的变革——CLI 不再仅仅是人与内核的接口，正在进化为人、AI 与系统资源三者协作的通用总线。
(报告结束)
引用来源
1 Gemini Deep Research 技术解析 2 Model Context Protocol (MCP) 核心文档与 CLI 集成 13 Headless Browser MCP Servers (Puppeteer/Playwright) 5 AGENTS.md 模式与 Agent 状态管理 4 Ralph Loop 模式与 Shell 编排逻辑 15 Filesystem MCP 与本地配置 14 文档解析与 Markdown 转换工具 11 Agent 停止准则与反思机制 8 Copilot CLI 配置文件路径与优先级 17 Copilot CLI 自动授权标志 (--allow-all-tools)
引用的著作
Gemini 深度研究技术解析
MCP servers with the Gemini CLI, 访问时间为 一月 28, 2026， https://geminicli.com/docs/tools/mcp-server/
MCP Lifecycle Explained: Client–Server Workflow, 访问时间为 一月 28, 2026， https://medium.com/@ashishpandey2062/mcp-lifecycle-explained-client-server-workflow-c366fd45328b
PowerShell Ralph Loop for GitHub Copilot CLI - Based on David Fowler's bash script and Geoffrey Huntley's Ralph pattern for autonomous AI coding agents, 访问时间为 一月 28, 2026， https://gist.github.com/shanselman/aa5e34a74b36404123dabed9394655f3
How to write a great agents.md: Lessons from over 2,500 repositories - The GitHub Blog, 访问时间为 一月 28, 2026， https://github.blog/ai-and-ml/github-copilot/how-to-write-a-great-agents-md-lessons-from-over-2500-repositories/
Improve your AI code output with AGENTS.md (+ my best tips) - Builder.io, 访问时间为 一月 28, 2026， https://www.builder.io/blog/agents-md
Backcast MCP Server, 访问时间为 一月 28, 2026， https://mcpservers.org/servers/net-of-being/backcast-mcp-server
Managing GitHub Copilot CLI MCP Server Configuration in Your Repository, 访问时间为 一月 28, 2026， https://dev.to/mikoshiba-kyu/managing-github-copilot-cli-mcp-server-configuration-in-your-repository-58i6
Choose a design pattern for your agentic AI system | Cloud Architecture Center, 访问时间为 一月 28, 2026， https://docs.cloud.google.com/architecture/choose-design-pattern-agentic-ai-system
Use MCP servers in VS Code, 访问时间为 一月 28, 2026， https://code.visualstudio.com/docs/copilot/customization/mcp-servers
Agents are just “LLM + loop + tools” (it's simpler than people make it) : r/LangChain - Reddit, 访问时间为 一月 28, 2026， https://www.reddit.com/r/LangChain/comments/1mynq4a/agents_are_just_llm_loop_tools_its_simpler_than/
Browser MCP | Awesome MCP Servers, 访问时间为 一月 28, 2026， https://mcpservers.org/servers/bytedance/browser-mcp
TheSethRose/Fetch-Browser: A powerful headless browser MCP server that enables AI agents to fetch web content and perform Google searches without requiring any API keys. - GitHub, 访问时间为 一月 28, 2026， https://github.com/TheSethRose/Fetch-Browser
Fetcher MCP - Servers, 访问时间为 一月 28, 2026， https://mcpservers.org/servers/jae-jae/fetcher-mcp
MarcusJellinghaus/mcp_server_filesystem: MCP File System Server: A secure Model Context Protocol server that provides file operations for AI assistants. Enables Claude and other assistants to safely read, write, and list files in a designated project directory with robust path validation and security controls. - GitHub, 访问时间为 一月 28, 2026， https://github.com/MarcusJellinghaus/mcp_server_filesystem
MCP-MD-PDF: Markdown to Word/PDF Converter | Awesome MCP Servers, 访问时间为 一月 28, 2026， https://mcpservers.org/servers/sham-devs/mcp-md-pdf
GitHub Copilot CLI: Plan before you build, steer as you go - GitHub Changelog, 访问时间为 一月 28, 2026， https://github.blog/changelog/2026-01-21-github-copilot-cli-plan-before-you-build-steer-as-you-go/
Automating the Github Copilot Agent from the command line with Copilot CLI | R-bloggers, 访问时间为 一月 28, 2026， https://www.r-bloggers.com/2025/10/automating-the-github-copilot-agent-from-the-command-line-with-copilot-cli/
browserbase/mcp-server-browserbase: Allow LLMs to control a browser with Browserbase and Stagehand - GitHub, 访问时间为 一月 28, 2026， https://github.com/browserbase/mcp-server-browserbase
MCP Web Browser Server by random-robbie - Glama, 访问时间为 一月 28, 2026， https://glama.ai/mcp/servers/@random-robbie/mcp-web-browser
parruda/headless-browser-tool: MCP Server with a headless Chrome browser based on Capybara and Selenium. Works with SSE and STDIO - GitHub, 访问时间为 一月 28, 2026， https://github.com/parruda/headless-browser-tool
MCP servers configured but tools not exposed to AI assistant in Copilot CLI #191 - GitHub, 访问时间为 一月 28, 2026， https://github.com/github/copilot-cli/issues/191
